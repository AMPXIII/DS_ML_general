{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Customized confusion matrix plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create basic Log Reg ann plot some metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_basic_lr(X_train, y_train, X_test, y_test, model_name):\n",
    "    basic_lr = LogisticRegression()\n",
    "    basic_lr.fit(X_train, y_train)\n",
    "    print('Accuracy: ',accuracy_score(y_test,basic_lr.predict(X_test)))\n",
    "    print('F1-Score: ',f1_score(y_test,basic_lr.predict(X_test)))\n",
    "    print('ROC AUC: ',roc_auc_score(y_test,basic_lr.predict(X_test)))\n",
    "    cm = confusion_matrix(y_test,basic_lr.predict(X_test))\n",
    "    plot_confusion_matrix(cm, ['Not Survived','Survived'],\n",
    "                              normalize=False,\n",
    "                              title='Confusion matrix',\n",
    "                              cmap=plt.cm.Oranges)\n",
    "    return basic_lr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot proba dist (on test set) from binary clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_proba_dist_binary_clf(clf_bin, X_test, y_test):\n",
    "    \n",
    "    p_test_lr = clf_bin.predict_proba(X_test)[:,1]\n",
    "    df_a = pd.DataFrame({\"target\":y_test, \"pred_probas\":p_test_lr})\n",
    "    \n",
    "    plt.figure(figsize=(12,6))\n",
    "    _ = sns.distplot(df_p[df_p[\"target\"]==1].loc[:,\"pred_probas\"],bins=20,kde=False,color=\"g\")\n",
    "    _ = sns.distplot(df_p[df_p[\"target\"]==0].loc[:,\"pred_probas\"],bins=20,kde=False,color=\"b\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same for multiclass classifier (OVR: One VS Rest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_proba_dist_multiclass(clf_multi, X_test, y_test):\n",
    "    \"\"\"\n",
    "    Func. that takes a previously trained multiclass classifier (one that outputs probabilities)\n",
    "    and prints a series of distplots with the probability distribution of each predicted class\n",
    "    VS the rest.\n",
    "    This makes sense when the aforesaid classifier has been trained using One-VS-Rest logic.\n",
    "    \"\"\"\n",
    "    \n",
    "    pred = clf_multi.predict(X_test)\n",
    "    pred_proba = clf_multi.predict_proba(X_test)\n",
    "    \n",
    "    dict_proba = {}\n",
    "    for i in range(pred_proba.shape[1]):\n",
    "        dict_proba[\"Proba_\"+str(i)] = pred_proba[:,i]\n",
    "\n",
    "    dict_proba[\"Label\"] = pred\n",
    "    \n",
    "    df_a = pd.DataFrame(data=dict_proba)\n",
    "\n",
    "    fig, axs = plt.subplots(pred_proba.shape[1], 1, figsize=(12, 6 * pred_proba.shape[1]))\n",
    "    for i in range(pred_proba.shape[1]):\n",
    "        for j in range(pred_proba.shape[1]):\n",
    "            if i == j:\n",
    "                _ = sns.distplot(df_a[df_a[\"Label\"]==j].loc[:,\"Proba_\"+str(i)],bins=20,kde=False,color=\"g\",ax=axs[i],norm_hist=True)\n",
    "            else:\n",
    "                _ = sns.distplot(df_a[df_a[\"Label\"]==j].loc[:,\"Proba_\"+str(i)],bins=20,kde=False,color=\"b\",ax=axs[i],norm_hist=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train a series of classifiers and compute their F1-Scores (or any other classification metric from those available in sklearn)\n",
    "Then plot these metrics on a horizontal barplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier, ExtraTreesClassifier, VotingClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score, StratifiedKFold, learning_curve\n",
    "\n",
    "kfold = StratifiedKFold(n_splits=10)\n",
    "\n",
    "random_state = 0\n",
    "classifiers = []\n",
    "classifiers.append(SVC(random_state=random_state))\n",
    "classifiers.append(DecisionTreeClassifier(random_state=random_state))\n",
    "classifiers.append(AdaBoostClassifier(DecisionTreeClassifier(random_state=random_state),random_state=random_state,learning_rate=0.1))\n",
    "classifiers.append(RandomForestClassifier(random_state=random_state))\n",
    "classifiers.append(ExtraTreesClassifier(random_state=random_state))\n",
    "classifiers.append(GradientBoostingClassifier(random_state=random_state))\n",
    "classifiers.append(MLPClassifier(random_state=random_state))\n",
    "classifiers.append(KNeighborsClassifier())\n",
    "classifiers.append(LogisticRegression(random_state = random_state))\n",
    "classifiers.append(LinearDiscriminantAnalysis())\n",
    "\n",
    "cv_results = []\n",
    "for classifier in classifiers :\n",
    "    cv_results.append(cross_val_score(classifier, X_train, y = y_train, scoring = \"f1\", cv = kfold, n_jobs=-1))\n",
    "\n",
    "cv_means = []\n",
    "cv_std = []\n",
    "for cv_result in cv_results:\n",
    "    cv_means.append(cv_result.mean())\n",
    "    cv_std.append(cv_result.std())\n",
    "    \n",
    "cv_res = pd.DataFrame({\"CrossValMeans\":cv_means,\"CrossValerrors\": cv_std,\"Algorithm\":[\"SVC\",\"DecisionTree\",\"AdaBoost\",\n",
    "\"RandomForest\",\"ExtraTrees\",\"GradientBoosting\",\"MultipleLayerPerceptron\",\"KNeighboors\",\"LogisticRegression\",\"LinearDiscriminantAnalysis\"]})\n",
    "\n",
    "g = sns.barplot(\"CrossValMeans\",\"Algorithm\",data = cv_res, palette=\"Set3\",orient = \"h\",**{'xerr':cv_std})\n",
    "g.set_xlabel(\"Mean F1-Score\")\n",
    "g = g.set_title(\"Cross validation scores\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyper-parameter tuning using Grid-Search CV for a Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold = StratifiedKFold(n_splits=10)\n",
    "\n",
    "# RFC Parameters tunning \n",
    "RFC = RandomForestClassifier()\n",
    "\n",
    "\n",
    "## Search grid for optimal parameters\n",
    "rf_param_grid = {\"max_depth\": [None],\n",
    "              \"max_features\": [1, 3, 10, 20],\n",
    "              \"min_samples_split\": [2, 3, 10, 15],\n",
    "              \"min_samples_leaf\": [1, 3, 10],\n",
    "              \"bootstrap\": [False],\n",
    "              \"n_estimators\" :[100,200,300,400],\n",
    "              \"criterion\": [\"gini\",\"entropy\"]}\n",
    "\n",
    "\n",
    "gsRFC = GridSearchCV(RFC,param_grid = rf_param_grid, cv=kfold, scoring=\"f1\", n_jobs= -1, verbose = 1)\n",
    "\n",
    "gsRFC.fit(X_train_imp_eng,y_train)\n",
    "\n",
    "RFC_best = gsRFC.best_estimator_\n",
    "\n",
    "# Best score\n",
    "gsRFC.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot features importance rankings for different (pre-trained) tree-based algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nrows = ncols = 2\n",
    "fig, axes = plt.subplots(nrows = nrows, ncols = ncols, sharex=\"all\", figsize=(15,15))\n",
    "\n",
    "names_classifiers = [(\"AdaBoosting\", ada_best),(\"ExtraTrees\",ExtC_best),(\"RandomForest\",RFC_best),(\"GradientBoosting\",GBC_best)]\n",
    "\n",
    "nclassifier = 0\n",
    "for row in range(nrows):\n",
    "    for col in range(ncols):\n",
    "        name = names_classifiers[nclassifier][0]\n",
    "        classifier = names_classifiers[nclassifier][1]\n",
    "        indices = np.argsort(classifier.feature_importances_)[::-1][:20]\n",
    "        g = sns.barplot(y=X_train_imp_eng.columns[indices][:20],x = classifier.feature_importances_[indices][:20] , orient='h',ax=axes[row][col])\n",
    "        g.set_xlabel(\"Relative importance\",fontsize=12)\n",
    "        g.set_ylabel(\"Features\",fontsize=12)\n",
    "        g.tick_params(labelsize=9)\n",
    "        g.set_title(name + \" feature importance\")\n",
    "        nclassifier += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
